---
title: RNN
created: 2025-12-17
tags:
  - deep_learning
links:
  - "[[Feedforward Neural Network]]"
---
**Определение:** *Рекуррентная нейронная сеть (RNN)* - это любая сеть, содержащая цикл в своих сетевых связях, то есть значение некоторого элемента прямо или косвенно зависит от его собственных предыдущих выходных данных, которые являются входными.

Такие сети сложны для анализа и обучения. Но в общем классе рекуррентных сетей существуют ограниченные архитектуры, которые оказались чрезвычайно эффективными при применению к языку. Рассмотрим класс RNN, называемых сетями Элмана или простыми RNN. Эти сети полезны сами по себе и служат основой для более сложных подходов, таких как сети с долговременной кратковременной памятью(LSTM).

![[Pasted image 20251217173828.png]]

На рисунке выше изображена структура RNN. Как с простыми сетями прямого распространения, входной вектор, представляющий текущие входные данные $x_{t}$, умноженный на матрицу весов и затем проходит через нелинейную функцию активации, чтобы вычислить значения для слоя скрытых юнитов. Это скрытый слой затем используется для вычисления соответствующего вывода, $y_{t}$. В отличие от нашего предыдущего подхода, основанного на окнах, обработка последовательностей осуществляется путем предъявления сети по одному элементу за раз. Будем использовать индексы для обозначения времени, таким образом, $x_{t}$ будет означать входной вектор $x$ в момент времени $t$.

Ключевое отличие от сети прямого распространения заключается в рекуррентной связи, показанной на рисунке пунктирной линией. Эта связь дополняет входные данные для вычислений в скрытом слое значением скрытого слоя из предыдущего момента времени. Скрытый слой из предыдущего временного шага обеспечивает своего рода память, или контекст, который кодирует предыдущую обработку и определяет решения, которые должны быть приняты в более поздние моменты времени. Важно отметить, что этот подход не накладывает ограничение фиксированной длины на этот предыдущий контекст, контекст, воплощенный в предыдущем скрытом слое, может включать информацию, простирающуюся до начала последовательности.

Добавление этого временного измерения создает впечатление, что рекуррентные нейронные сети сложнее, чем нерекуррентные архитектуры. Но на самом деле они не так сильно отличаются. Имея входной вектор и значения для скрытого слоя с предыдущего скрытого шага, по-прежнему выполняется стандартный прямой вычислительный процесс.

![[Pasted image 20251217180137.png]]

На рисунке рекуррентная нейронная сеть представлена в виде сети прямого распространения, и в целом, природу рекуррентности и то, как она влияет на вычисления в скрытом слое. Наиболее существенное изменение заключается в новом наборе весов $U$, которые соединяют скрытый слой предыдущего временного шага с текущим скрытым слоем. Эти веса определяют, как сеть использует предыдущий контекст при вычислении выходных данных для текущих входных данных. Как и другие веса в сети, эти связи обучаются с помощью обратного распространения ошибки.

#### Вывод(Inference) в RNN
 Прямой вывод (отображение последовательности входных данных в последовательность выходных данных) в RNN почти идентична тому, что есть в сетях прямого распространения. Чтобы вычислить выходные данные $y_{t}$ для входных данных $x_{t}$, нам необходимо значение активации для скрытого слоя $h_{t}$. Чтобы вычислить это, мы умножаем входные данные $x_{t}$ с матрицей весов $W$, и скрытый слой из предыдущего временного шага $h_{t-1}$ с матрицей весов $U$. Мы складываем эти значения вместе и пропускаем их подходящую функцию активации, $g$, чтобы получить значение активации для текущего скрытого слоя $h_{t}$. После того, как мы получили значения для скрытого слоя, мы переходим к обычным вычислениям для генерации выходного вектора:
 $$
\begin{array} \\
\mathrm{h}_{t}= g(\mathrm{Uh}_{t-1}+\mathrm{Wx}_{t}) \\
\mathrm{y}_{t}=f(\mathrm{Vh}_{t})
\end{array}
$$
Обозначим размеры входного, скрытого и выходного слоев как $d_{in}, d_{h}$ и $d_{out}$ соответственно. Зная это, наши 3 матрицы параметров: $W\in \mathbb{R}^{d_{h}\times d_{in}},\ \mathrm{U}\in \mathbb{R}^{d_{h}\times d_{h}}$ и $\mathrm{V}\in \mathbb{R}^{d_{out}\times d_{h}}$.
Вычислим $y_{t}$ с помощью вычисления softmax, которая дает вероятностное распределение по всевозможным классам выхода.
$$
\mathrm{y}_{t}=\mathrm{softmax}(\mathrm{Vh}_{t})
$$

Факт, что вычисление в момент времени $t$ требует значение скрытого слоя из момента времени $t-1$, обуславливает использование алгоритма инкрементального вывода(инференса), который выполняется от начала последовательности до конца, как показано в алгоритме ниже.

```pseudo
\begin{algorithm}
\caption{Forward RNN}
\begin{algorithmic}
\Require input sequence $x$, network parameters
\Ensure output sequence $y$

\State $h_0 \gets 0$
\For{$i = 1$ to $\mathrm{Length}(x)$}
    \State $h_i \gets g(U h_{i-1} + W x_i)$
    \State $y_i \gets f(V h_i)$
\EndFor

\State \Return $y$
\end{algorithmic}
\end{algorithm}
```
Последовательный характер простых рекуррентных сетей также можно увидеть, развернув сеть во времени, как показано ниже. Различные матрицы весов являются общими для всех временных интервалов.

![[Pasted image 20251217184808.png]]

#### Обучение

Как и с сетями прямого распространения, будет использоваться обучающая выборка, функция потерь и обратное распространение для получения градиентов, необходимых для корректировки весов в этих рекуррентных сетях. То есть есть 3 набора весов для обновления: $\mathrm{W}$ - веса от входного слоя к скрытому слою, $\mathrm{U}$ - веса от предыдущего скрытого слоя к текущему скрытому слою, и, наконец, $\mathrm{V}$ - веса от скрытого слоя к выходному слою.

На рисунке выше показаны два момента, о которых нам не приходилось беспокоиться при обратном распространении ошибки в сетях прямого распространения. Во-первых, для вычисления функции потерь для выхода в момент времени $t$ на нужен скрытый слой из момента времени $t-1$. Во-вторых, скрытый слой в момент времени $t$ влияет как на выход в момент времени $t$, так и на скрытый слоя в момент времени $t+1$ (и, следовательно, на выход и потери в момент времени $t+1$). Из этого следует, что для оценки ошибки, возникающей в $h_{t}$, нам необходимо знать её влияние как на текущий выход, так и на последующие.

Адаптация алгоритма обратного распространения ошибки к данной ситуации приводит к двупроходному алгоритму обучения весов в рекуррентных нейронных сетях. На первом проходе выполняется прямой инференс, вычисляя $h_{t}$, $y_{t}$, накапливая функцию потерь на каждом шаге для использования на следующем шаге. На втором проходе мы обрабатываем последовательность в обратном порядке, вычисляя необходимые градиенты по мере продвижения, вычисляя и сохраняя член ошибки для использования в скрытом слое на каждом шаге назад во времени. Этот общий подход обычно называют *обратным распространением ошибки во времени*.

К счастью, благодаря современным вычислительным платформам и достаточным вычислительным ресурсам, нет необходимости в специализированном подходе к обучению рекуррентных сетей (RNN). Как показано выше на рисунке явное развертывание рекуррентной сети в прямой вычислительный граф исключает любые явные рекуррентные связи, позволяя обучать веса сети напрямую. В таком подходе мы предоставляем шаблон, определяющий базовую структуру сети, включая все необходимые параметры для входного, выходного и скрытого слоев, матрицы весов, а также используемые функции активации и выхода. Затем, при наличии определенной входной последовательности, мы можем сгенерировать развернутую прямую сеть, специфичную для этой входной последовательности, и использовать этот граф для выполнения прямого инференса или обучения с помощью обратного распространения ошибки.

Для приложений, включающих гораздо более длинные входные последовательности, таких как распознавание речи, обработка на уровне символов или потоковая передача непрерывных входных данных, развертывание всей входной последовательности может быть нецелесообразным. В этих случаях мы можем развернуть входные данные на управляемые сегменты фиксированной длины и рассматривать каждый сегмент как отдельный обучающий элемент.