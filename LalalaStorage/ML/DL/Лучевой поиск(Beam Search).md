---
title: Лучевой поиск(Beam Search)
created: 2025-12-09
tags:
  - deep_learning
links:
---
Алгоритм *лучевого поиска* поддерживает несколько вариантов выбора, пока мы не увидим, какой из них лучше.

В лучевом поиске мы моделируем декодирование как поиск в пространстве возможных генераций, представленных как *дерево поиска*, где *ветви* представляют действия(генерацию токена), и вершины, представляемых состояния(генерация определенного префикса). Мы ищем наилучшую последовательность действий, т.е. строку с наибольшей вероятностью.

В *лучевом поиске*, вместо выбора лучшего токена для генерации в каждой временной метки, мы сохраняем $k$ возможных токенов на каждом шаге. Этот след в памяти фиксированного размера $k$ называется *шириной луча*.

Таким образом в первом шаге декодинга, мы вычисляем softmax по целому словарному запасу, присваивая каждому слову вероятность. Затем выбирается $k$-лучших вариантов из вывода softmax. Эти изначальные $k$ выходов составляют границу поиска, эти $k$ изначальных слов называются *гипотезами*. *Гипотеза* - выходная последовательность, вместе с её вероятностью.

![[Pasted image 20251209221759.png]]

На последующих шагах каждая из $k$ лучших гипотез постепенно расширяется, передаваясь различным декодерам, каждый из которых генерирует softmax по всему словарю, чтобы расширить гипотезу на все возможные токены. Каждая их этих $k\times V$ гипотез оценивается формулой $P(y_{i}\ | \ x,y_{<i})$: произведение вероятности текущего слова на вероятность пути, который к нему привел. Затем мы сокращаем $k\times V$ гипотез до $k$ лучших, так что на границе поиска не бывает более $k$ декодеров.

Процесс продолжается, пока не будет сгенерирован токен $\mathrm{EOS}$, указывающий на то, что полный кандидат был найден. В этот момент завершенная гипотеза удаляется из границы, а размер пучка уменьшается на единицу. Поиск продолжается, пока луч не сократится до нуля. Результатом будет $k$ гипотез. 

Для оценки каждой вершины по его логарифмической вероятности, мы используем цепное правило вероятности, чтобы разложить $p(y\ | \ x)$ в произведение вероятностей каждого слова с учетом его предыдущего контекста, которое мы можем преобразовать в сумму логарифмов:

$$
\begin{array} \\
\mathrm{score}(y)&= \log P(y\ | \ x) \\
&=\log(P(y_{1}\ | \ x)P(y_{2}\ | \ y_{1},x)P(y_{3}\ | \ y_{1},y_{2},x)\dots P(y_{t}\ | \ y_{1},\dots,y_{t-1},x)) \\
&=\sum_{i=1}^{t}\log P(y_{i}\ | \ y_{1},\dots,y_{i-1},x)
\end{array}
$$

Таким образом, на каждом шаге, чтобы вычислить вероятность частичного предложения, мы просто добавляем логарифм вероятности префиксного предложения к логарифму вероятности генерации следующего токена.

![[Pasted image 20251209225419.png]]

Ниже представлен алгоритм. Одна из проблем этой версии алгоритма заключается в том, что готовые гипотезы могут иметь разную длину. Поскольку языковые модели обычно присваивают низкую вероятность более длинным строкам, наивный алгоритм выбирал бы более короткие строки для $y$. По этой причине часто применяют методы нормализации длины, например деление логарифма вероятности на количество слов:
$$
\mathrm{score}(y)= \frac{1}{t} \log P(y\ | \ x)= \frac{1}{t} \sum_{i=1}^{t}\log P(y_{i}\ | \ y_{1},\dots,y_{i-1},x)
$$

![[Pasted image 20251209230607.png]]

### Декодирование с минимальным риском Байеса

Декодирование с *минимальным риском Байеса* или *MBR* - альтернатива алгоритму декодинга, который может работать даже лучше, чем поиск луча и также, как правило, лучше других алгоритмов декодирования, таких как выборка по температуре.

Идея минимального риска Байеса в том, что вместо попытки выбрать наиболее вероятную последовательность, выбрать последовательность, которая, вероятно, будет иметь наименьшую ошибку. 

На практике мы не знаем идеальный набор выходных данных для входной последовательности. Поэтому стандартное упрощение, используемое в алгоритмах декодирования MBR, заключается в выборе такой выходной последовательности, наиболее схожими с некоторым набором возможных последовательностей. По сути. мы аппроксимируем огромное пространство всех возможных последовательностей $\mathcal{U}$ меньшим набором возможных последовательностей-кандидатов $\mathcal{Y}$.

Зная этот набор возможных кандидатов-последовательностей $\mathcal{Y}$, и некоторую функцию сходства или выравнивания util, мы выберем лучшую последовательность $\mathcal{Y}$ как последовательность, самую близкую к другим кандидатам-последовательности:
$$
\hat{y}=\mathrm{argmax}_{y\in \mathcal{Y}}\sum_{c\in \mathcal{Y}}\mathrm{util}(y,c)
$$
Можно использовать различные функциями-утилит. Можно получить набор кандидатов на вывод, используя один из алгоритмов выборки.