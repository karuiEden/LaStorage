---
title: CTC
created: 2025-12-28
tags:
  - deep_learning
  - nlp
links:
  - "[[Задача распознавания речи]]"
---
Распознавание речи обладает двумя особыми свойствами, которые делают его очень подходящим для архитектуры кодирощик-декодер, где кодировщик создает кодировку входных данных, которую декодер использует с механизмом внимания для анализа. Во-первых, в речи мы имеем очень длинную входную акустическую последовательность $X$, отображающуюся на гораздо более короткую последовательность букв $Y$, и, во-вторых, трудно точно определить, какая часть $X$ соответствует какой части $Y$.

В этом разделе кратко представим альтернативу кодировщику-декодеру: алгоритм и функцию потерь, называемые *CTC*, сокращение от *Connectionist Temporal Classification*, которые решают эти проблемы совершенно иным способом. Идея CTC заключается в том, чтобы выводить один символ для каждого кадра входных данных, так что выходные данные имеют ту же длину, что и входные, а затем применяют функцию объединения, которая комбинирует последовательности одинаковых букв, в результате чего получается более короткая последовательность.

Представим себе вывод о том, что кто-то произносит слово "dinner", и предположим, что у нас есть функция, которая выбирает наиболее вероятную букву для каждого спектрального кадра представления $x_{i}$. Мы назовем последовательность букв, соответствующих каждому входному кадру, выравниваем, потому что она показывает, где в акустическом сигнале каждая буква выравнивается с этим выравниваем. На рисунке ниже показано одно такое выравнивание и то, что произойдет, если мы используем функцию свёртывания, которая просто удаляет последовательные повторяющиеся буквы.

Что ж, это не работает, наш наивный алгоритм транскрибировал речь как diner, а не dinner. Функция свертывания не обрабатывает повторяющиеся буквы. Есть также еще одна проблема с нашей наивной функцией; она не указывает нам, какой символ нужно выравнивать с тишиной во входных данных. Мы же не хотим транскрибировать тишину как случайные буквы!

![[Pasted image 20251228151321.png]]

Алгоритм CTC решает обе проблемы, добавляя в алфавит транскрипции специальный символ для *пробела*, который мы будем обозначать как $\textvisiblespace$.  Пробел можно использовать в выравнивании всякий раз, когда мы не хотим транскрибировать букву. Пробел также можно использовать между буквами; поскольку наша функция свертывания сворачивает только последовательные повторяющиеся буквы. она не будет сворачивать между $\textvisiblespace$ .Более формально, давайте определим отображение $B:a\to y$ между выравниваем $a$ и выходными данными $y$, которое сворачивает все повторяющиеся буквы и затем удаляет все пробелы. На рисунке ниже изображена эта функция $B$.

![[Pasted image 20251228152141.png]]

Функция свертывания CTC является отображением "многие к одному"; множество различных выравниваний отображается на одну и ту же строку. Например, выравнивание, показанное на рисунке выше, не является единственным выравниваем, которое приводит к строке dinner. На рисунке ниже показаны некоторые другие выравнивания, которые дадут тот же результат.

![[Pasted image 20251228152444.png]]

Полезно представить себе множество выравниваний, которые могут дать одинаковый результат: $Y$. Мы будем использовать обратную функцию к нашей функции $B$, называемую $B^{-1}$, и представим это множество как $B^{-1}(Y)$.

### CTC Инференс

Прежде чем рассматривать вычисление $P_{CTC}(Y\ | \ X)$, давайте сначала рассмотрим, как CTC присваивает вероятность одному конкретному выравниваю $\hat{A}=\{ \hat{a}_{1},\dots,\hat{a}_{n} \}$. CTC делает сильное предположение об условной независимости: оно предполагает, что при заданном входном значении $X$ выходные данные модели CTC в момент времени $t$ независимы от выходных меток в любой момент времени $a_{i}$. Таким образом:
$$
P_{CTC}(A\ | \ X) = \prod_{t=1}^{T}p(a_{t}\ | \ X)
$$
Таким образом, чтобы найти наилучшее выравнивание $\hat{A}=\{ \hat{a}_{1},\dots,\hat{a}_{T} \}$, мы можем жадным методом выбирать символ с максимальной вероятностью на каждом шаге времени $t$:
$$
\hat{a}_{t}= \text{argmax}_{c\in C}\ p_{t}(c\ | \ X)
$$
Затем мы передаем полученную последовательность $A$ функции свертывания CTC $B$, чтобы получить выходную последовательность $Y$.

Давайте рассмотрим, как будет реализован этот простой алгоритм вывода для поиска наилучшего выравнивания $A$. Поскольку мы принимаем решение в каждый момент времени, мы можем рассматривать CTC как задачу моделирования последовательности, где мы выводим одну букву в момент времени $t$, соответствующую каждому входному токену $x_{t}$, что исключает необходимость в полном декодере. На рисунке ниже схематично изображена эта архитектура, где мы берем кодировщик, создаем скрытое состояние $h_{t}$ на каждом шаге времени и декодируем, выполняя операцию softmax над словарем символов на каждом шаге времени.

![[Pasted image 20251228161948.png]]

К сожалению, в алгоритме инференса, описанном в уравнении выше и рисунке над уравнением, есть потенциальный недостаток. Проблема в том, что мы выбрали наиболее вероятное выравнивание $A$, но наиболее вероятное выравнивание может не соответствовать наиболее вероятной итоговой свернутой выходной строке $Y$. Это потому, что существует множество возможных выравниваний, которые приводят к одной и той же выходной строке, и, следовательно, наиболее вероятная выходная строка может не соответствовать наиболее вероятному выравниванию. Например, представим, что наиболее вероятное выравнивание $A$ для входа $X=[x_{1},x_{2},x_{3}]$ - это строка $[a,b,c]$, но следующие два наиболее вероятных выравнивания - это $[b,c,b]$ и $[c,b,b]$ Выход $Y=[b,b]$, суммирующий значения этих двух выравниваний, может быть более вероятным, чем $Y=[a,b,c]$.

По этой причине наиболее вероятной выходной последовательностью $Y$ является та, которая имеет не единственное наилучшее выравнивание CTC, а наибольшую сумму вероятностей все возможных событий:
$$
P_{CTC}(Y\ | \ \mathrm{X})=\sum_{A\in B^{-1}(Y)}P(A\ | \ \mathrm{X}) = \sum_{A\in B^{-1}(Y)}\prod_{t=1}^{T}p(a_{t}\ | \ h_{t})
$$
$$
\hat{Y}=\text{argmax}_{Y} P_{CTC}(Y\ | \ \mathrm{X})
$$
К сожалению, суммирование по всем выравниваниям очень затратно, поэтому мы аппроксимируем эту сумму, используя версию алгоритма поиска по лучу Витерби, которая умело сохраняет в луче выравнивания с высокой вероятностью, которые отображаются на одну и ту же выходную строку, и суммирует их как приближение.

Из-за упомянутого раннее сильного предположения об условной независимости, CTC не обучается неявно языковой модели на данных. Поэтому при использовании CTC крайне важно интерполировать языковую модель с помощью весов интерполяции, обученных на данных для разработки:
$$
\text{score}_{CTC}(Y\ | \ \mathrm{X})=\log P_{CTC}(Y\ | \  \mathrm{X})+\lambda_{1}\log P_{LM}(Y)\lambda_{2}L(Y)
$$
### CTC обучение

Чтобы обучить ASR систему, основанную на CTC, используется отрицательный логарифм правдоподобия со специальной CTC функцией потери. Таким образом, потеря для целого датасета $D$ сумма негативных логарифмических правдоподобий корректного выхода для каждого входа $X$:
$$
L_{CTC}=\sum_{(X,Y)\in D}-\log P_{CTC}(Y\ | \ \mathrm{X})
$$

Чтобы вычислить CTC функцию потери для единый входной пары $(\mathrm{X},Y)$, нам необходима вероятность выходных данных $Y$, имея входные данные $\mathrm{X}$. Чтобы вычислить вероятность выходных данных $Y$ нам необходимо просуммировать по всем возможным выравниваниям, которые приведут к $Y$. Другими словами:
$$
P_{CTC}(Y\ | \ \mathrm{X})=\sum_{A\in B^{-1}(Y)}\prod_{t=1}^{T}p(a_{t}\ | \ h_{t})
$$
Наивное суммирование по всем возможным выравниваем нецелесообразно. Однако мы можем эффективно вычислить сумму, используя динамическое программирование для слияния выравниваний, при этом версия алгоритма *прямого-обратного прохода* также используется для обучения скрытых марковских моделей и CRF.

### Комбинация CTC и Encoder-Decoder

Также возможно объединить две описанные нами архитектуры/функции потерь: кросс-энтропийную потерю из архитектуру кодировщик-декодер и потерю CTC. На рисунке ниже показана схема. Для обучения мы можем просто взвесить две функции потерь с помощью $\lambda$, настроенного на наборе данных для разработки:
$$
L=-\lambda \log P_{encdec}(Y\ | \ \mathrm{X})-(1-\lambda)\log P_{CTC}(Y\ | \ \mathrm{X})
$$
Для вывода мы можем объединить эти два подхода с языковой моделью (или штрафом за длину), опять же с использованием обученных весов:
$$
\hat{Y}=\text{argmax}_{Y} [\lambda \log P_{encdec}(Y\ | \ \mathrm{X})-(1-\lambda)\log P_{CTC}(Y\ | \ \mathrm{X})+\gamma \log P_{LM}(Y)]
$$
![[Pasted image 20251228165705.png]]


### Потоковые модели: RNN-T для улучшения CTC

Из-за сильного предположения о независимости в алгоритме CTC, распознаватели на основе CTC не достигают такой высокой точности, как распознаватели на основе механизма "кодиковщик-декодер" с механизмом внимания. Однако распознаватели CTC имеют преимущество в том, что их можно использовать для *потоковой обработки*. Потоковая обработка означает распознавание слов в режиме реального времени, а не ожидание до конца предложения для их распознавания. Потоковая обработка имеет решающее значение для многих приложений, от команд до диктовки, где мы хотим начать распознавание, пока пользователь еще говорит. Алгоритмы, использующие механизм внимания, должны сначала вычислить скрытое состояние последовательности по всему входному сигналу, чтобы обеспечить контекст распределения внимания, прежде чем декодер сможет начать декодирование. В отличие от этого, алгоритм CTC может вводить буквы слева направо немедленно.

Если мы хотим использовать потоковую передачу, нам нужен способ улучшить распознавание CTC, чтобы исключить предположение об условной независимости и позволить ему знать историю выходных данных. *RNN-Transducer (RNN-T)*, показанный на схеме ниже. RNN-T имеет два основных компонента: акустическую модель CTC и отдельный компонент языковой модели, называемый предиктором, который учитывает историю выходных токенов. На каждом шаге времени $t$ кодировщик CTC выдает скрытое состояние $h^{enc}_{t}$ при заданных входных данных $x_{1}\dots x_{t}$. Предиктор языковой модели принимает на вход предыдущий выходной токен, выдавая скрытое состояние $h^{pred}_{u}$. Оба значения передаются через другую сеть, выход которой затем передается через функцию softmax для предсказания следующего символа.
$$
P_{\text{RNN-T}}(Y\ | \ \mathrm{X})=\sum_{A\in B^{-1}(Y)}P(A\ | \ \mathrm{X}) = \sum_{A\in B^{-1}(Y)}\prod_{t=1}^{T}p(a_{t}\ | \ h_{t}, y_{<u_{t}})
$$
![[Pasted image 20251228172924.png]]

