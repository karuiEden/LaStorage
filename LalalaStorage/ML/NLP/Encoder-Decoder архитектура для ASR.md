---
title: Encoder-Decoder архитектура для ASR
created: 2025-12-28
tags:
  - deep_learning
  - nlp
links:
  - "[[Задача распознавания речи]]"
  - "[[Кодер-декодер архитектура]]"
---
Первая архитектура ASR, которую мы представляем, - это архитектура кодировщика-декодера, та же самая архитектура, которая была представлена раннее. На рисунке ниже схематически изображена эта архитектура, называемая кодировщиком-декодером на основе внимания или *AED*, или *listen attend and spell* (LAS) в честь двух статей, в которых она впервые была применена к речи.

Входными данными для архитектуры является последовательность $x$ из $t$ акустических векторов $X=x_{1},x_{2},\dots,x_{t}$, по одному вектору на кадр 10 мс. Мы часто начинаем с логарифмических мел-спектральных признаков, описанных раннее, хотя также возможно начать с сырого wav-файла. Выходная последовательность $Y$ может представлять собой либо буквы, либо токены; Для упрощения объяснения будем считать. что это буквы. Таким образом, выходная последовательность $Y=(<SOS>, y_{1},\dots,y_{m},<EOS>)$, предполагая специальные начальные и конечные токены последовательности \<sos> и \<eos>, причем каждый $y_{i}$ является символом; для английского языка мы могли бы выбрать следующий набор:
$$
y_{i}\in \{ a,b,\mathbf{c},\dots,z,0,\dots,9,< \text{space}>, <\text{comma}>, <\text{period}>, <\text{apostrophe}>, <\text{unk}> \}
$$

![[Pasted image 20251228113041.png]]

Эта архитектура также используется в модели Whisper от OpenAI. На рисунке ниже показана часть архитектуры Whisper. Модели Whisper и код вывода общедоступны, но код обучения и обучающие данные - нет. Однако существуют проекты с открытым исходным кодом, использующие архитектуру в стиле Whisper, такие как Open Whisper-style Speech Model (OWSM), которая воспроизводит обучение в стиле Whisper, но предлагает полностью открытый набор инструментов и общедоступные данные.

![[Pasted image 20251228113536.png]]

### Входной и сверточные слои

Архитектура кодировщика-декодера особенно подходит в случаях, когда входные и выходные последовательности имеют существенные различия в длине, как это бывает в речи, когда длинные последовательности акустических признаков соответствуют гораздо более коротким последовательностям букв или слов. Например, в английском языке слова в среднем состоят из 5 букв или 1.3 BPE-токенов, а в естественной речи среднее слово длится около 250 мс , или 25 кадров по 10 мс. Таким образом, речевой сигнал в 10-миллисекундных кадрах примерно в 5 (25 / 5) - 19 (25 / 1.3) раз длиннее текстового сигнала в словах или токенах.

Поскольку эта разница в длине настолько существенна для речи, архитектуры кодировщика-декодера для речи обычно имеют этап сжатия, который укорачивает последовательность акустических признаков перед этапом кодирования. Цель субдискретизации - получить более короткую последовательность $X=x_{1},\dots,x_{n}$, которая будет входным сигналом для кодировщика-трансформатора. Очень простой базовый алгоритм  - это метод, иногда называемый низкой частотой кадров: для времени $i$ мы объединяем вектор акустических признаков $f_{i}$ с двумя предыдущими векторами $f_{i-1}$ и $f_{i-2}$, чтобы создать новый вектор в три раза длиннее. Затем мы просто удаляем $f_{i-1}$ и $f_{i-2}$.

Таким образом, вместо 40-мерного вектора акустических признаков каждые 10 мс, мы получаем более длинный вектор каждые 30 мс с меньшей длиной последовательности $n = \frac{t}{3}$.

Но наиболее распространенный способ создания более короткой входной последовательности - использование сверточных слоев, которые мы представили в предыдущем разделе. Когда сверточный слой имеет шаг больше 1, выходная последовательность становится короче входной. Давайте рассмотрим это на примере двух широко используемых систем распознавания речи. 

Система Whisper имеет контекстное окно аудио длительностью 30 секунд. Она извлекает 128-канальные логарифмические мел-признаки для каждого кадра с окном 25 мс и шагом 10 мс. Затем они нормализуются до среднего значения 0 и диапазона от -1 до 1. Шаг 10 мс означает, что в 30-секундном контекстном окне содержится 3000 входных кадров. Эти 3000 кадров передаются на два сверточных слоя за каждым из которых следует нелинейность. Первый сверточный слой имеет 128 входных каналов и шаг 1, при этом количество входных и выходных каналов равно размерности модели, а длина окна составляет 3000. Для второго сверточного слоя количество входных и выходных каналов равно размерности модели, и шаг равен 2. Шаг 2 во втором сверточном слое уменьшает длину выходной последовательности вдвое, по сравнению с входной, уменьшая длину выходного окна до 1500 и создавая аудиотокен каждые 20 мс. Синусоидальные позиционные эмбеддинги добавляются к этим аудиокодировкам перед тем, как выход этого интерфейса будет передан в кодировщик-трансформер.

HuBERT использует альтернативную архитектуру фронтенда, в которой сверточные слои используются для полной замены вычисления спектра. Таким образом, входными данными является необработанный аудиосигнал с частотой дискретизации 16 кГц, который проходит через семь 512-канальных слоев с шагами $[5,2,2,2,2,2,2]$ и шириной ядра $[10,3,3,3,3,2,2]$, которые обучаются как извлекать спектральную информацию, так и сокращать входную последовательность в 320 раз, с 16 кГц до частоты кадров 20 мс. К входным данным добавляются позиционные кодировки, а затем применяются GELU и нормализация слоя, прежде чем выходные данные передаются в кодировщик-трансформер.

### Инференс

После сверточной обработки кодировщики-декодеры для речи используют ту же архитектуру, что и для машинного перевода. Она использует два трансформера: кодировщик, который аналогичен базовому трансформеру кодировщику, и декодер, который имеет одно дополнение: новый слой, называемый слоем *перекрестного внимания*. Кодировщик принимает акустический вход $X=x_{1},\dots,x_{n}$ и отображает его в выходное представление $H^{enc}=h_{1},\dots,h_{n}$; с помощью стека блоков кодировщика.

Декодер по сути представляет собой условную языковую модель, которая учитывает представление кодировщика и генерирует целевой текст по одному, на каждом шаге времени, с учетом аудиопредставлений от кодировщика и раннее сгенерированного текста для генерации новой буквы или токена.

Блоки трансформеров в декодере имеют дополнительный слой со специальным типом внимания, перекрестным вниманием. Перекрестное внимание имеет ту же форму, что и многоловочное внимание в обычном блоке трансформера, за исключением того, что, в то время как запросы, как обычно, поступают из предыдущего слоя декодера, ключи и значения поступают с выхода кодировщика. То есть, если в стандартном многоловочном внимании является $X$, то в перекрестном внимании входом является конечный выход кодировщика $H^{enc}=h_{1},\dots,h_{n}$. $H^{enc}$ имеет форму $[n\times d]$, каждая строка представляет собой один акустический входной токен. Чтобы связать ключи и значения из кодировщика с запросов из предыдущего слоя декодера, мы умножаем выход кодировщика $H^{enc}$ на веса ключей $W^{K}$ и веса значений $W^{V}$ слоя перекрестного внимания.  Запрос поступает из выходных данных предыдущего декодера: слоя $H^{dec[\ell-1]}$, который умножается на веса запроса слоя перекрестного внимания $W^{Q}$:
$$
Q=H^{dec[\ell-1]}W^{Q};\quad K=H^{enc}W^{K};\quad V=H^{enc}W^{V}
$$
$$
\text{CrossAttention}(Q, K, V)= \text{softmax}\left(  \frac{QK^{T}}{\sqrt{ d_{k} }}  \right)V
$$
Таким образом, перекрестное внимание позволяют декодеру обращать внимание на акустический вход, проецируемый на все выходные представления кодировщика. Другой слой внимания, в каждом блоке декодера, многоголовочный слой внимания. представляет собой то же самое причинное внимание. Но многоголовочный слой внимания в кодировщике, однако, может смотреть вперед на весь текст на исходном языке, поэтому он не маскируется. 

Для выхода вероятность выходной строки $y$ разлагается следующим образом:
$$
p(y_{1},\dots,y_{n})=\prod_{i=1}^{n}p(y_{i}\ | \ y_{1},\dots,y_{i-1}, X)
$$
Мы можем получить каждую букву выходных данных с помощью жадного декодирования:
$$
\hat{y}_{i}=\text{argmax}_{\text{char}\in\text{Alphabrt}}P(\text{char}\ | \ y_{1}\dots y_{i-1},X)
$$
В качестве альтернативы, кодировщики-декодеры, такие как Whisper или OWSM, также используют поиск по лучу, как описано в следующем разделе. Это особенно актуально, когда мы добавляем языковую модель.

*Добавление языковой модели*. Поскольку модель кодировщика-декодера является условной языковой моделью, кодировщики-декодеры неявно обучаются языковой модели для выходной области букв на основе своих обучающих данных. Однако обучающие данные могут не содержать достаточного количества текста для обучения хорошей языковой модели. В конце концов, найти огромные объемные чисто текстовых обучающих данных проще, чем найти текст в паре с речью. Таким образом, мы обычно можем улучшить модель, по крайней мере, немного, включив очень большую языковую модель. 

Самый простой способ сделать это - использовать поиск по лучу, чтобы получить итоговый луч гипотетических предложений; этот луч иногда называют *списком n-лучших*. Затем мы используем языковую модель для переоценки каждой гипотезы в луче. Оценка производится путем интерполяции оценки, присвоенной языковой моделью, с оценкой кодировщика-декодера, используемой для создания луча, с весом $\lambda$, настроенным на отложенном наборе данных. Кроме того, поскольку большинство моделей предпочитают более короткие предложения, системы автоматического распознавания речи обычно имеют какой-либо способ добавления фактора длины. Один из способов сделать это - нормализовать вероятность по количеству символов в гипотезе $|Y|_{c}$. Ниже приведена функция оценки для Listen, Attend и Spell:
$$
\text{score}(Y\ | \ \mathrm{X})= \frac{1}{|Y|_{c}} \log P(Y\ | \ \mathrm{X})+\lambda \log P_{LM}(Y)
$$

### Обучение

Модель кодировщика-декодера обучаются методом кросс-энтропии и обратного распространения ошибки, как и остальные модели этой архитектуры.

