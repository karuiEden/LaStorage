---
title: Токенизация
created: 2025-11-06
tags:
  - nlp
links:
---
**Определение:** Токенизация - процесс сегментации входного текста в токены.

**Определение:** Токен - минимальная единица текста, с которой работает модель.

В соверменных моделях часто используют два алгоритма:
- [[Byte-pair encoding(BPE)]];
- Unigram language modeling(ULM).
