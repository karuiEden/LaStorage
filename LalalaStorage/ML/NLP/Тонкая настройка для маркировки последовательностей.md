---
title: Тонкая настройка для маркировки последовательностей
created: 2025-12-04
tags:
  - nlp
links:
  - "[[Двунаправленные энкодер-трансформеры]]"
---
### Именованная сущность

*Именованная сущность*, грубо говоря, представляет собой всё что угодно, что можно связать с именем собственным: личность, локация, организация. Задача распознавания именованных сущностей заключается в поиске фрагментов текста, которые представляют собой имена собственные, и обозначить тип сущности. Наиболее распространены 4 тэга сущностей: **PER** (личность), **LOC** (локация), **ORG** (организация) **GPE**(геополитическая сущность). В то же время, термин *именованной сущности* обычно расширяется на то, что не является сущностью, как таковыми, включая временные выражения, такие как даты и время, и даже числовые выражения, такие как цены.
Пример вывода NER тэггера:
Citing high fuel prices, [ORG United Airlines] said [TIME Friday] it has increased fares by [MONEY $6] per round trip on flights to some cities also served by lower-cost carriers. [ORG American Airlines], a unit of [ORG AMR Corp.], immediately matched the move, spokesman [PER Tim Wagner] said. [ORG United], a unit of [ORG UAL Corp.], said the increase took effect [TIME Thursday] and applies to most routes where it competes against discount carriers, such as [LOC Chicago] to [LOC Dallas] and [LOC Denver] to [LOC San Francisco].

Текст содержит 13 упоминаний именованных сущностей, включая 5 организаций, 4 локации, 2 времени и 1 упоминание денег. Многие приложения будут также требовать использование специальных типов сущностей, такие как белки, гены, коммерческие продукты и произведения искусства.

Распознавание именованных сущностей является полезным шагом в задачах обработки естественного языка, включая связывание текста с информацией в структуированных базах знаний. Задача NER сложна из-за неоднозначности сегментации NER-фрагментов, понимания, какие токены являются сущностью, а какие нет, так как большинство слов в тексте не являются именованными сущностями. Другая проблема вызвана неоднозначностью типов.

![[Pasted image 20251204155303.png]]

Пример выше, что один токен является разными сущностями.

### BIO тегирование

Один из стандартных подходов маркировки последовательностей для задач распознавания фрагментов, таких как NER, является *BIO тегирование*. Этот метод позволяет нам рассматривать NER как задачу пословной маркировки последовательности с помощью тэгов, которые фиксируют как границу, так и именованный тип сущности. Рассмотрим текст:
[PER Jane Villanueva ] of [ORG United] , a unit of [ORG United Airlines
Holding] , said the fare applies to the [LOC Chicago ] route.

На рисунке ниже показан тот же фрагмент текста, представленный с тегированием BIO, а также с вариантами, называемыми тегированием IO и тегированием BIOES. При тегировании мы помечаем любой токен, начинающий интересующий интервал, буквой B, токены, находящиеся внутри интервала, буквой I, а все токены, находящиеся вне интервала, помечаем буквой O. Хотя существует только один тег O, для каждого именованного класса сущности будут использоваться отдельные теги B и I. Таким образом, количество тегов равно $2n+1$, где $n$ - количество типов сущностей. Разметка BIO может представлять точно такую же информацию, как и запись в скобках, но имеет то преимущество, что мы можем представить задачу тем же простым способом моделирования последовательности, что и разметка частей речи: присваивая одну метку $y_{i}$ каждому входному токену $x_{i}$. Мы также показали два варианта разметки: IO, которая теряет часть информации, удаляя тег B, и разметка BIOES, которая добавляет конечный тег E для конца интервала и тег S для интервала, состоящего только из одного слова.

![[Pasted image 20251204214942.png]]

### Маркировка последовательностей

В маркировке последовательностей, мы пропускаем выходной вектор, соответствующий каждому входному токену через классификатор, который генерирует распределение softmax по возможному набору тегов. Для классификатора однослойной сети прямого распространения набор обученных весов равен $W_{K}$ размера $[d\times k]$, где $k$ - число возможных тегов для задачи. Жадный подход, где максимальный по аргументу тег для каждого токена будет взят как вероятный ответ, может использоваться для генерации выходной последовательности тегов.

![[Pasted image 20251204220438.png]]

$$
\begin{array} \\
y_{i}=\text{softmax}(h_{i}^{L}W_{K}) \\
t_{i}=\text{argmax}_{k}(y_{i})
\end{array}
$$
Или же, распределение по всем меткам, сгенерированное softmax, для каждого входного токена может быть пропущено через слой условного случайного поля, который может учитывать глобальные переходы на уровне тегов.

#### Токенизация и NER

Заметьте, что обучающие данные с ответами для NER обычно представлены в виде тегов BIO, связанных с текстом, сегментированным на уровне слов. Например, следующее предложение, содержащее две именованные сущности:
[LOC Mt. Sanitas ] is in [LOC Sunshine Canyon] .
может иметь соответствующий набор пословного BIO-тега:
Mt. Sanitas is in Sunshine Canyon .
B-LOC I-LOC O O B-LOC I-LOC O

К сожалению, последовательность WordPiece токенов для этого предложения напрямую не совпадает с BIO-тегами в аннотации:

’Mt’, ’.’, ’San’, ’##itas’, ’is’, ’in’, ’Sunshine’, ’Canyon’ ’.’

Чтобы избавиться от этого несоответствием, нам нужен способ назначения тегов BIO токенам подслов во время обучения и соответствующий способ восстановления тегов на уровне слов из подслов во время декодирования. Для обучения мы можем просто  назначить стандартный тег, связанный с каждым словом, всем токенам подслов, полученным из него.

Для декодирования простейший метод - использовать тег $\text{argmax}$ BIO, связанный с первым токеном подслова слова. Таким образом, в нашем примере тег BIO, назначенный "Mt", будет назначен "Mt.", а тег, назначенный "San", будет назначен "Sanitas", фактически игнорируя информацию в тегах, назначенных остальным подсловам слов, рассмотренных раннее. Более сложные подходы комбинируют распределение вероятностей тегов по подсловам, пытаясь найти оптимальный тег на уровне слов.

### Оценка распознавания именованных сущностей

Распознаватели именованных сущностей оценивают с помощью метрик [[Метрики качества классификации#Precision и recall|recall, precision]] и [[Метрики качества классификации#F-мера|F1-метрики]].

Чтобы узнать, является ли разница между результатами $F_{1}$ двух систем NER значимой, используется парный бутстрап тест или аналогичный рандомизированный тест.

При маркировке именованных сущностей, единицей ответа является сама сущность, а не слово.

Тот факт, что маркировка именованных сущностей зависит от степени сегментации текста, которое отсутствует в таких задачах, как категоризация текста или маркировка частей речи, вызывает проблемы с оценкой. Кроме того, использование сущностей в качестве единицы ответа, а слов в качестве единицы обучения означает несоответствие между условиями обучения и тестирования.