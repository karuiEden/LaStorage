---
title: Bias-Variance decomposition
created: 2025-10-01
tags:
  - ml
links:
---
**Определение:** Ошибка модели складывается из трех факторов: сложность выборки, сходства модели с истинной зависимостью ответов от объектов в выборке, и богатства семейства, из которого выбирается модель. Между ними существует некоторый баланс, и уменьшение одного из них приводит к увеличению другого. Такое разложение ошибки называется *разложения на смещение и разброс*.

*Вывод* **Bias-Variance decomposition**:

Пусть задана выборка $X=(x_{i},y_{i})_{i=1}^{\ell}$ с вещественными ответами $y_{i}\in \mathbb{R}$. Будем считать, что на пространстве всех объектов и ответов $\mathbb{X}\times \mathbb{Y}$ существует распределение $p(x,y)$, из которого сгенерирована выборка $X$ и ответы на ней

Рассмотрим квадратичную функцию потерь
$$L(y,a)=(y-a(x))^{2}$$
и соответствующий ей среднеквадратичный риск $$R(a)=\mathbb{E}_{x,y}[(y-a(x))^{2}]=\int_{\mathbb{X}}\int_{\mathbb{Y}}p(x,y)(y-a(x))^{2}dxdy.$$
Данный функционал усредняет ошибку модели в каждой точке пространства $x$ и для каждого возможного ответа $y$, причем вклад пары $(x,y)$, по сути, пропорционален вероятности получить её в выборке $p(x,y)$. Разумеется, на практике мы не можем вычислить данный функционал, поскольку распределение $p(x,y)$ неизвестно. Тем не менее, в теории, он позволяет измерить качество модели на всех возможных объектах, а не только на обучающей выборке.

### Минимум среднеквадратичного риска

Покажем, что минимум среднеквадратичного риска достигается на функции, возвращающей условное матожидание ответа при фиксированном объекте:
$$a_{*}(x)=\mathbb{E}_{x,y}[y\ |\ x]=\int_{\mathbb{Y}}yp(y \ |\ x)dy= \arg_{a}\min R(a)$$
Преобразуем функцию потерь:
$$L(y,a(x))=(y-a(x))^{2}=(y-\mathbb{E}(y\ |\ x)+\mathbb{E}_{x,y}(y\ |\ x)-a(x))^{2}=$$
$$=(y-\mathbb{E}(y\ |\ x))^{2}+2(y-\mathbb{E}(y\ |\ x))(\mathbb{E}(y\ | \ x)-a(x))+ (\mathbb{E}(y\ |\ x)-a(x))^{2}$$
Подставим её в функционал среднеквадратичного риска:
$$R(a)=\mathbb{E}_{x,y}L(y,a(x))=\mathbb{E}_{x,y}(y-\mathbb{E}(y\ |\ x))^{2}+\mathbb{E}_{x,y}(\mathbb{E}(y\ |\ x)-a(x))^{2}+$$
$$+2\mathbb{E}_{x,y}(y-\mathbb{E}(y\ |\ x))(\mathbb{E}(y\ |\ x)-a(x))$$
Разберёмся с последним слагаемым. Перейдём от матожидания $\mathbb{E}_{x,y}[f(x,y)]$ к цепочке матожиданий $$\mathbb{E}_{x}\mathbb{E}_{y}[f(x,y)\ |\ x]=\int_{\mathbb{X}}\left( \int_{\mathbb{Y}}f(x,y)p(y\ |\ x)dy \right)p(x)dx$$
и заметим, что величина $(\mathbb{E}(y\ |\ x)-a(x))$ не зависит от $y$, поэтому её можно вынести за матожидание по $y$:
$$\mathbb{E}_{x,y}[(y-\mathbb{E}(y\ |\ x))(\mathbb{E}(y\ |\ x)-a(x))\ | \ x]=\mathbb{E}_{x}((\mathbb{E}(y\ |\ x)-a(x)))\mathbb{E}_{y}[(y-\mathbb{E}(y\ |\ x))\ |\ x]=$$
$$=\mathbb{E}_{x}((\mathbb{E}(y\ |\ x)-a(x)))(\mathbb{E}(y\ |\ x)-\mathbb{E}(y\ |\ x))=0$$
Получаем, что функционал среднеквадратичного риска имеет вид:
$$R(a)=\mathbb{E}_{x,y}(y-\mathbb{E}(y\ |\ x))^{2}+\mathbb{E}_{x,y}(\mathbb{E}(y\ | \ x)-a(x))^{2}$$
От алгоритма $a(x)$ зависит только второе слагаемое, и оно достигает своего минимума, если $a(x)=\mathbb{E}(y\ |\ x)$. Таким образом оптимальная модель регрессии для квадратичной функции потерь имеет вид:
$$a_{*}(x)=\mathbb{E}(y\ |\ x)=\int_{\mathbb{Y}}yp(y\ |\ x)dy$$
То есть, мы должны провести "взвешенное голосование" по всем возможным ответам, причем вес ответа равен его апостериорной вероятности.

### Ошибка метода обучения

Для того, чтобы построить идеальную функцию регрессии, необходимо знать распределение на объектах и ответах $p(x,y)$, что, как правило, невозможно. На практике вместо этого выбирается некоторый *метод обучения* $\mu:(\mathbb{X}\times \mathbb{Y})^{\ell}\to \mathcal{A}$, который произвольной обучающей выборке ставит в соответствие некоторый алгоритм из семейства $\mathcal{A}$. В качестве меры качества метода обучения можно взять усреднённый по всем выборка среднеквадратичный риск алгоритма, выбранного методом $\mu$ по выборке: 
$$L(\mu)=\mathbb{E}_{X}[\mathbb{E}_{x,y}[(y-\mu(X)(x))^{2}]]= $$

$$=\int_{(\mathbb{X}\times \mathbb{Y})^{\ell}}\int_{\mathbb{X}\times \mathbb{Y}}(y-\mu(X)(x))^{2}p(x,y)\prod_{i=1}^{\ell}p(x_{i},y_{i})dxdydx_{1}dy_{1}\dots dx_{\ell}dy_{\ell} \ \ \ \ (2.1)$$ ^e255ee

Здесь матожидание $\mathbb{E}_{X}[\cdot]$ берется по всем возможным выборкам $\{ (x_{1},y_{1}),\dots,(x_{\ell},y_{\ell}) \}$ из распределения $\prod_{i=1}^{\ell}p(x_{i},y_{i})$.

Обратим внимание, что результатом применения метода обучения $\mu(X)$ к выборке $X$ является модель, поэтому правильно писать $\mu(X)(x)$, но для сокращения записей в дальнейшем используем $\mu(X)$, но при этом это всё равно функция от $x$.
Выше показано, что среднеквадратичный риск на фиксированной выборке можно расписать как
$$\mathbb{E}_{x,y}[(y-\mu(X))^{2}]=\mathbb{E}_{x,y}[(y-\mathbb{E}[y\ | \ x])^{2}]+\mathbb{E}_{x,y}[(\mathbb{E}[y\ |\ x]-\mu(X))^{2}]$$
Подставим это выражение в ([[#^e255ee|2.1]]):
$$L(\mu)=\mathbb{E_{X}}\underbrace{[\mathbb{E}_{x,y}[(y-\mathbb{E}[y|x])^{2}]]}_{\text{не зависит от }X}+\mathbb{E}_{x,y}[(\mathbb{E}[y|x]-\mu(X))^{2}]=$$

$$
=\mathbb{E}_{x,y}[(y-\mathbb{E}[y|x])^{2}]+\mathbb{E}_{x,y}[\mathbb{E}_{X}[(\mathbb{E}[y|x]-\mu(X))^{2}]]. \ \ \ \ (2.2)
$$

^097cbb

Преобразуем второе слагаемое:
$$\mathbb{E}_{x,y}[\mathbb{E}_{X}[(\mathbb{E}[y|x]-\mu(X))^{2}]]=\mathbb{E}_{x,y}\bigg[\mathbb{E}_{X}\bigg[ (\mathbb{E}[y|x]-\mathbb{E}_{X}[\mu(X)] +\mathbb{E}_{X}[\mu(X)]-\mu(X))^{2}  \bigg]\bigg]=$$
$$\mathbb{E}_{x,y}\bigg[ \mathbb{E}_{X}\bigg[ \underbrace{(\mathbb{E}[y|x] - \mathbb{E}_{X}[\mu(X)])^{2}}_{\text{не зависит от X}} \bigg] \bigg]+\mathbb{E}_{x,y} \bigg[ \mathbb{E}_{X}\bigg[ (\mathbb{E}_{X}[\mu](X) -\mu(X))^{2}\bigg] \bigg]+$$

$$2\mathbb{E}_{x,y}\bigg[ \mathbb{E}_{X}\bigg[ (\mathbb{E}[y\ | \ x] -\mathbb{E}_{X}[\mu(X)])(\mathbb{E}_{X}[\mu(X)]-\mu(X)) \bigg] \bigg]. \ \ \ (2.3)$$ ^550b65

Покажем, что последнее слагаемое обращается в нуль:
$$\mathbb{E}_{X}\bigg[ (\mathbb{E}[y\ | \ x]-\mathbb{E}_{X}[\mu(X)])(\mathbb{E}_{X}[\mu(X)-\mu(X)]) \bigg]=(\mathbb{E}[y\ | \ x]-\mathbb{E}_{X}[\mu(X)])\mathbb{E}_{X}(\mathbb{E}_{X}[\mu(X)]-\mu(X))=$$
$$=(\mathbb{E}[y\ | \ x]-\mathbb{E}_{X}[\mu(X)])\bigg[ \mathbb{E}_{X}[\mu(X)] - \mathbb{E}_{X}[\mu(X)] \bigg]=0$$
Учитывая это, подставим ([[#^550b65|2.3]]) в ([[#^097cbb|2.2]]):

$$
L(\mu)=\underbrace{\mathbb{E}_{x,y}\bigg[ (y-\mathbb{E}[y\ | \ x])^{2} \bigg]}_{\text{шум}}+\underbrace{\mathbb{E}_{x}\bigg[ (\mathbb{E}_{X}[\mu(X)]-\mathbb{E}[y\ | \ x])^{2} \bigg]}_{\text{смещение}}+\underbrace{\mathbb{E}_{x}\bigg[ \mathbb{E}_{X} \bigg[ (\mu(X)-\mathbb{E}_{X}[\mu(X)])^{2} \bigg] \bigg]}_{\text{разброс}} \ \ \ (2.4)
$$
Рассмотрим подробнее компоненты полученного разложения ошибки. Первая компонента характеризует *шум* в данных и равна ошибке идеального алгоритма. Невозможно построить алгоритм, имеющий меньшую среднеквадратичную ошибку. Вторая компонента характеризует *смещение* (*bias*) метода обучения, то есть отклонение среднего ответа обученного алгоритма от ответа идеального алгоритма. Третья компонента характеризует *дисперсию* (*variance*), то есть разброс ответов обученных алгоритмов относительного среднего ответа.

Смещение показывает, насколько хорошо с помощью данных метода обучения и семейства алгоритмов можно приблизить оптимальный алгоритм. Как правило, смещение маленькое у сложных семейств(например, деревьев) и большое у простых семейств (например, линейных классификаторов). Дисперсия показывает, насколько сильно может изменяться ответ обученного алгоритма в зависимости от выборки - иными словами, она характеризует чувствительность метода обучения к изменениям в выборке. Как правило, простые семейства имеют маленькую дисперсию, а сложные семейства - большую дисперсию.
![[Pasted image 20251002103216.png]]

На рисунке изображены модели с различным сдвигом и разбросом. Модели изображены синимы точками, одна точка соответствует модели, обученной по одной из возможных обучающих выборок. Каждый круг характеризует качество модели - чем ближе точка к центру, тем меньше ошибок на контрольной выборке достигает данный алгоритм.

**Замечание:** Разложение ошибки на три компоненты, которое мы только что вывели, верно только для квадратичной функции потерь. Существуют более общие формы этого разложения(*Domingos, Pedro (2000). A Unified Bias-Variance Decomposition and its Applications*), которые состоят из 3 компонент с аналогичным смыслом, поэтому можно утверждать, что для большинства распространённых функций потерь ошибка метода обучения складывается из шума, смещения и разброса; значит, и дальнейшие рассуждения про изменения этих компонент в композициях также можно обобщить на другие функции потерь.