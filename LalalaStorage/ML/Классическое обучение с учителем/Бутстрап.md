---
title: Бутстрап
created: 2025-10-01
tags:
  - ml
  - statistics
links:
---
Рассмотрим простой пример построения композиции алгоритмов. Пусть дана конечная выборка $X=(x_{i},y_{i})$ с вещественными ответами. Будем решать задачу линейной регрессии. Сгенерируем подвыборку с помощью *бутстрапа*. Равномерно возьмём из выборки $\ell$ объектов с возвращением. Отметим, что из-за возвращения среди них окажутся повторы. Обозначим новую выборку через $X_{1}$. Повторив процедуру $N$ раз, сгенерируем $N$ подвыборок $X_{1},\dots,X_{n}$. Обучим по каждой из них линейную модель регрессии, получив *базовые алгоритмы* $b_{1}(x),\dots,b_{N}(x)$.
Предположим, что существует истинная функция ответа для всех объектов $y(x)$, а также задано распределение на объектах $p(x)$. В этом случае запишем ошибку каждой функции регрессии
$$\varepsilon_{j}(x)=b_{j}(x)-y(x), \ \ j=1,\dots N,$$
и записать мат ожидание среднеквадратичной ошибки

$$\mathbb{E}_{x}(b_{j}(x)-y(x))^{2}=\mathbb{E}_{x}\varepsilon_{j}^{2}(x).$$
Средняя ошибка построенных функций регрессии имеет вид
$$E_{1}= \frac{1}{N}\sum_{j=1}^{N}\mathbb{E}_{x}\varepsilon_{j}^{2}(x).$$
Предположим, что ошибки несмещены и некоррелированы:
$$\mathbb{E}_{x}\varepsilon_{j}(x)=0;$$
$$\mathbb{E}_{x}\varepsilon_{i}(x)\varepsilon_{j}(x)=0, \ \ i\neq j$$
Построим теперь новую функцию регрессии, которая будет усреднять ответы постронных нами функций:
$$a(x)= \frac{1}{N}\sum_{j=1}^{N}b_{j}(x).$$
Найдем её среднеквадратичную ошибку:
$$E_{N}=\mathbb{E}_{x}\left( \frac{1}{N}\sum_{j=1}^{N}b(j) - y(x) \right)^{2}=\mathbb{E}_{x}\left( \frac{1}{N}\sum_{j=1}^{N}\varepsilon_{j}(x) \right)^{2}=\frac{1}{N^{2}}\mathbb{E}_{x}\left( \sum_{j=1}^{N}\varepsilon_{j}^{2}(x)+\underbrace{\sum_{i\neq j}\varepsilon_{i}(x)\varepsilon_{j}(x)}_{=0} \right)= $$
$$=\frac{1}{N}E_{1}$$
Таким образом, усреднение ответов позволило уменьшить средний квадрат ошибки в $N$ раз.
Но данный пример не очень применим на практике, ибо было сделано предположение о некоррелированности ошибок, что редко выполняется. Если это предположение неверно, то уменьшение ошибки будет не таким значительным. 