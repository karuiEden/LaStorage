---
title: Решающее деревья
created: 2025-09-22
tags:
  - ml
  - decision_tree
links:
---
**Определение:** *Бинарное решающее дерево* - это алгоритм $a(x)$, действующий в бинарном дереве, в котором:
- каждой внутренней вершине $v$ приписана функция (или предикат) $\beta_{v}:\mathbb{X}\to \{ 0,1 \}$;
- Каждой листовой вершине приписан прогноз $c_{v}\in Y$ (в случае с классификацией листу может быть приписан вектор вероятностей).
стартующий из корня $v_{0}$ и вычисляет значение $\beta_{v_{0}}$. Если значение равно нулю, то алгоритм переходит в левое поддерево. Иначе, в правое. Всё это происходит, пока не достигается листовая вершина, алгоритм возвращает тот класс, который приписан этой вершине.

В большинстве случаев используются предикаты $\beta_{v}$, которые сравнивают значение одного из признаков с порогом:
$$\beta_{v}(x,j,t)=[x_{j}<t]$$
Существуют также и многомерные предикаты:
- линейные $\beta_{v}=[\langle w,x \rangle < t]$
- метрические $\beta_{v}=[\rho(x,x_{0})<t]$, где $x_{0}$ является одним из объектов выборки любой точкой признакового пространства.
 Многомерные предикаты позволяют строить ещё более сложные разделяющие поверхности, но редко используются на практике, так как усиливают переобучение.
 
 Главный недостаток решающего дерева - это высокая переобучаемость, при этом в композиции они работают очень эффективно.
### Построение деревьев

Так как решающее дерево легко переобучается, то построить идеальное решающее дерево на обучающей выборке не составит труда. Поэтому поставим задачу поиска дерева, которое является минимальным по количеству листьев, среди всех деревьев, не допускающих ошибок на обучающей выборке - в этом случае можно понадеяться на наличие у дерева обобщающей способности. Но данная задача является $\text{NP}$-полной, поэтому приходится ограничиваться жадными алгоритмами построения дерева.

**Жадный алгоритм построения решающего дерева:**
1. Поиск лучшего разбиения на две части $R_{1}(j,t)=\{ x \ | \ x_{j}<t\}$ и $R_{2}(j,t)=\{ x \ | \ x_{j} \geq t \}$ с точки зрения заранее заданного функционала качества;
2. Поиск лучших значений $j$ и $t$. Создание предиката $[x_{j} < t]$;
3. Рекурсивное повторение шагов 1 и 2 до выполнения условия останова.
4. Объявление текущей вершины листовой и ставим в соответствие ответ:
	1.  Если задача классификацией, то ответом может быть класс, к которому относится больше всего объектов в листе, или вектор вероятностей (скажем, вероятность класса может быть равна доле его объектов в листе)
	2. Если задача регрессии, то это может быть среднее значение, медиана или другая функция от целевых переменных объектов в листе.

Решающие деревья могут обрабатывать пропущенные значения - ситуации, в которых для некоторых объектов неизвестны значения одного  или нескольких признаков. Для этого необходимо модифицировать процедуру разбиения выборки в вершине.

После того, как дерево построено, можно провести его *стрижку* ($\text{pruning}$) - удаление некоторых вершин с целью понижения сложности и повышения обобщающей способности.

Таким образом, конкретный метод построения решающего дерева определяется:
1. Видом предикатов в вершинах;
2. Функционалом качества $Q(X,j,t)$;
3. Критерием останова;
4. Методом обработки пропущенных значений;
5. Методом стрижки.

Также могут иметь место некоторые расширения, связанные с учётом весов объектов, работой с категориальными признаками и т.д.
