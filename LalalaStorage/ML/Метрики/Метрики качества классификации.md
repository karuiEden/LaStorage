---
title: Метрики качества классификации
created: 2025-08-10
tags:
  - ml
  - linear_models
links:
  - "[[Линейная классификация]]"
---
Пусть классификатор имеет вид:

$$a(x)=\sgn(b(x)-t)=2[b(x)>t]-1$$ ^bc0688

Линейная модель имеет форму, если $b(x)=\langle w,x \rangle,\ \ t=0$

## Доля правильных ответов

Наиболее очевидная метрика качества в задаче классификации является доля правильных ответов:
$$\DeclareMathOperator{\acc}{accuracy}\acc(a,x)=\frac{1}{\ell}\sum_{i=1}^{\ell}[a(x_{i})=y_{i}].$$
Данная метрика имеет существенный недостаток. Если взять порог $t$ меньше минимального значения прогноза $b(x)$ на выборке или больше максимального значения, то доля правильных ответов будет равна доле положительных или отрицательных ответов соответственно. 

Например, если в выборке $950$ отрицательных и $50$ положительных объектов. то при $t=\max_{i}(b(x_{i}))$ мы получим $\acc(a,x)=0.95$. Это означает, что $\acc$ не несет никакой информации о качестве работы алгоритма $a(x)$, и вместе с ней следует анализировать соотношение классов в выборке.

Также полезно вместе с $\acc$ вычислять *базовую долю*.
**Определение:** *Базовая доля* - доля правильных ответов алгоритма, всегда выдающего наиболее мощный класс.

Отметим, что при сравнении различных методов машинного обучения принято сообщать *относительное уменьшение ошибки*. Рассмотрим два алгоритма $a_{1}$ и $a_{2}$ с долями правильных ответов $r_{1}$ и $r_{2}$ соответственно, причем $r_{2}>r_{1}$.
**Определение:** *Относительное уменьшение ошибки* алгоритма $a_{2}$ - величина:
$$\frac{(1-r_{1})-(1-r_{2})}{1-r_{1}}$$
Если доля ошибок была улучшена с $20\%$ до $10\%$, то относительное улучшение составляет $50\%$. Если доля ошибок была улучшение с $50\%$ до $25\%$, то относительное улучшение также равно $50\%$, хотя данный прирост кажется более существенным. Если же доля ошибок была улучшена с $0.1\%$ до $0.01\%$, то относительное улучшение составляет $90\%$, что совершенно не соответствует здравому смыслу.
## Матрица ошибок
В случае несбалансированности классов помимо $\acc$ необходима ещё одна метрика качества.

**Определение:** Матрица ошибок - способ разбить объекты на четыре категории в зависимости от комбинации истинного ответа и ответа алгоритма:

|           | $y=1$                        | $y=-1$                       |
| --------- | ---------------------------- | ---------------------------- |
| $a(x)=1$  | $\text{True Positive (TP)}$  | $\text{False Positive (FP)}$ |
| $a(x)=-1$ | $\text{False Negative (FN)}$ | $\text{True Negative (TN)}$  |
Через элементы этой матрицы можно, например, выразить долю правильных ответов:
$$\acc= \frac{\text{TP}+\text{TN}}{\text{TP}+\text{FP}+\text{FN}+\text{TN}}$$
### Precision и recall
Введём на основе матрицы ошибок более информативные критерии:
**Определение:** *Точность (precision)* - доля объектов, выделенных классификатором как положительные, действительно являются положительными.
$$\DeclareMathOperator{\precision}{precision}\precision= \frac{\text{TP}}{\text{TP}+\text{FP}}$$
**Определение:** *Полнота* (recall) - доля положительных объектов, выделенная классификатором:
$$\DeclareMathOperator{\rec}{recall}\rec= \frac{\text{TP}}{\text{TP}+\text{FN}}$$
Рассмотрим, например, задачу предсказания реакции клиента банка на звонок с предложением кредита.  Пусть $y=1$, что клиент возьмёт кредит после звонка, $y=-1$ - не возьмёт. Соответственно, банк будет обзванивать только тех клиентов, для которых классификатор $a(x)$ вернет ответ $1$. Если классификатор будет иметь высокую *точность*, то практически все клиенты, которым будет сделан звонок, возьмут кредит. Если классификатор иметь высокую *полноту*, то предложение будет сделано почти всем клиентам, которые готовы откликнуться на него. Регулировать точность и полноту можно при помощи порога $t$ в [[#^bc0688|классификаторе]] $a(x)$. Если выбрать большое $t$, то классификатор будет относить к положительному классу меньше объектов, что приведёт к высокой точности и низкой полноте, если будем уменьшать $t$, то полнота будет возрастать, а точность падать.

При этом данные метрики не зависят от баланса классов, поэтому в случае несбалансированности классов метрики будут отражать качество модели корректно.
### F-мера 
Существует несколько способов получить один критерий качества на основе точности и полноты. Один из них - $F$ - мера.
**Определение:** *$F$-мера* - гармоническое среднее точности и полноты:
$$F= \frac{2*\precision*\rec}{\precision + \rec}.$$
Среднее гармоническое обладает важным свойством - оно близко к нулю, если хотя бы один из аргументов близок к нулю. Именно поэтому оно является более предпочтительным, чем среднее арифметическое. Можно заметить, что $F$-мера является сглаженной версией минимума из точности и полноты.
![[Pasted image 20250810133558.png]]

Отметим. что геометрическое среднее также похоже на сглаженный вариант минимума, но при этом оно менее устойчиво к "выбросам" - например, для точности $0.9$ и полноты $0.1$ гармоническое среднее будет равно $0.18$, а геометрическое среднее $0.3$.

### R-точность
Другим агретированным критерием является $R$-точность, или точка баланса (breakeven point).
**Определение:** *$R$-точность* - точность при таком $t$, при котором полнота равна точности:
$$\DeclareMathOperator{\rprec}{R-precision}\rprec=\precision(\sgn(b(x)-t^{*})),$$
$$t^{*}=\arg \min_{t} |\precision(\sgn(b(x)-t))-\rec(\sgn(b(x)-t))|.$$
Можно показать, что $R$-точность равна точности при таком пороге, при котором количество отнесённых к положительному классу объектов равно количеству положительных объектов в выборке.
### Средняя точность
Часто встречаются задачи, в которых целевой признак по-прежнему бинарный, но при этому необходимо ранжировать объекты, а не просто предсказывать их класс. И поскольку многие алгоритмы возвращают вещественный ответ $b(x)$, который затем бинаризируется по порогу $t$, то можно просто сортировать объекты по значению $b(x)$. Для измерения качества ранжирования нередко используют *среднюю точность*:
$$\text{AP}=\frac{1}{\ell_{+}}\sum_{i=1}^{\ell}[y_{(k)}=1]\precision @k,$$
где $y_{(k)}$ - ответ $k$-ого по порядку объекта $\ell_{+}$ - число положительных объектов в выборке, а $\precision@k$ - точность среди первых $k$ в списке объектов. Если алгоритм $b(x)$ так ранжирует объекты, что сначала идут все положительные, а затем все отрицательные, то средняя точность будет равна единице.

### Связь точности, полноты и доли правильных ответов

Выше было написано, что высокие значения доли правильных ответов не влекут за собой высокое качество работы классификатора, поэтому ввели точность и полноту, но необходимо осторожно подходить к требованиям к их значениям, потому что независимость этих метрик от соотношения классов может привести к неочевидным последствиям.
Рассмотрим пример в виде задачи бинарной классификации с миллионом объектов, где доля положительных классов составляет $1\%$. Из этого следует, что $\acc$ метрика будет вести себя не очень интуитивно, поэтому выберем точность и полноту, а также введём требования, чтобы они были не менее $90\%$. И теперь попробуем оценить, чему должна быть равна $\acc$ при таких полноте и точности.
Всего в выборке $10.000$ положительных объектов, и для достижения полноты $90\%$ мы должны отнести как минимум $9.000$ к положительному классу. Получаем $\text{TP}=9000,\text{FN}=1000$. Так как точность тоже должна быть не меньше $90\%$, то получаем $\text{FP}=1000$. Отсюда получаем, что $\acc= 1 - \frac{2.000}{1.000.000}=99.8\%$ . Это крайне высокий показатель и его редко получается достичь на таких выборках во многих предметных областях.
### Lift
**Применение:** Выбор подмножества
**Пример:** Выделение лояльных клиентов банка, уходящих пользователей мобильного оператора. Заказчика интересует вопрос, насколько выгодно работать с этим подмножеством по сравнению со всем множеством. Если при рассылке предложений о кредите клиентам из подмножества и всем клиентам будет получаться одна и та же доля откликнувшихся, то подмножество не будет представлять особой ценности. Формально это измеряется с помощью *прироста концентрации* (lift).

**Определение:** *Прирост концентрации* (lift) - величина, интерпретируемая как улучшение доли положительных объектов в данном подмножестве относительно доли в случайно выбранном подмножестве такого же размера:
$$\DeclareMathOperator{\lift}{lift}\lift= \frac{\precision}{(\text{TP}+\text{FN})/\ell}$$
## Area Under Curve

Выше были изучены метрики, которые характеризуют качество работы алгоритма $a(x)=\sgn(b(x)-t)$ при конкретном выборе порога $t$. Однако зачастую интерес представляет лишь алгоритм $b(x)$, а порог будет выбираться в зависимости от требований к точности и полноте. В таком случае возникает потребность в измерении качества семейства моделей $\{ a(x)=\sgn(b(x)-t) \ |\ t\in \mathbb{R} \}$.

Можно измерять качество этого множества на основе качества лучшего алгоритма. Для этого подходит точка баланса. В идеальном семействе алгоритмов она будет равна единице, так как найдется алгоритм, у которого полнота и точность будут равны $100\%$, но эта метрика основывается на качестве одной модели и не характеризует вариативность семейства.

Широко используется такая интегральная метрика, как *площадь под $ROC$-кривой* ($\text{Area Under ROC Curve, AUC-ROC}$). Рассмотрим двумерное пространство, одна из координат которого соответствует доле неверно принятых объектов($\text{False Positive Rate, FPR}$), а другая - доле верно принятых объектов ($\text{True Positive Rate, TPR}$):
$$\text{FPR} = \frac{\text{FP}}{\text{FP}+\text{TN}};$$
$$\text{TPR}= \frac{\text{TP}}{\text{TP}+\text{FN}}.$$
Каждый возможный выбор порога $t$ соответствует точке в этом пространстве. Всего различных порогов имеется $\ell+1$. Максимальный порог $t_{\max}=\max_{i}b(x_{i})$ даст классификатор с $\text{TPR}=0,\ \text{FPR}=0$. Минимальный порог $t_{\min}=\min_{i}b(x_{i})-\varepsilon$ даст $\text{TPR}=1,\ \text{FPR}=1$.
**Определение:** *$ROC$-кривая* - это кривая с концами в точках $(0,0)$ и $(1,1)$, которая последовательно соединяет точки, соответствующие порогам $b(x_{(1)})-\varepsilon,\ b(x_{(1)}),b(x_{(2)}),\dots,b(x_{(\ell)})$
![[Pasted image 20250811092541.png]]

**Определение:** $\text{AUC-ROC}$ - площадь под $ROC$-кривой. Принимает значения от $0$ до $1$. Если алгоритм $a(x)$ не допускает ошибок, то $\text{AUC-ROC}=1$, если же $b(x)$ ранжирует объекты случайным образом, то $\DeclareMathOperator{\AUCROC}{AUC-ROC}\AUCROC$ будет близок к $0.5$.

Критерий $\text{AUC}$ имеет большое число интерпретаций - например, он равен вероятности того, что для случайно выбранных положительного объекта $x_{+}$ и отрицательного объекта $x_{-}$ будет выполнено $b(x_{+})>b(x_{-})$. При условии, что прогнозы на всех объектах выборки попарно различны.

**Чувствительность к соотношению классов:** Если положительный класс существенно меньше по размеру, то $\AUCROC$ может давать неадекватную оценку, поскольку измеряет долю неверно принятых объектов относительно общего числа отрицательных.
### Индекс Джини

**Применение:** Задачи кредитного скоринга.
**Определение:** *Индекс Джини* - пропорциональная метрика вместо $\AUCROC$, равная удвоенной площади между $\text{ROC}$-кривой и диагональю, соединяющей точки $(0,0)$ и $(1,1)$.
$$\text{Gini}=2\cdot\text{AUC}-1$$
**Замечание:** Переход от $\AUCROC$ к индексу Джини приводит к увеличению относительных разниц. Если мы смогли улучшить $\text{AUC}$ c $0.8$ до $0.9$, то это соответствует относительному улучшению в $12.5\%$. В то же время соответствующие индексы Джини были улучшены с $0.6$ до $0.8$, то есть на $33\%$ - относительное улучшение повысилось почти в 3 раза.

### Precision-recall кривая

Проблема с несбалансированными классами решается к переходу к $\text{Precision-Recall}$ кривой. 
**Определение:** $\text{Precision-Recall}$ *кривая* - кривая, оси которой составляют полнота (по оси абсцисс) и точность (по оси ординат).

Критерием качества семейства алгоритмов выступает площадь под $\text{PR}$-кривой. Данную величину можно аппроксимировать следующим образом. Стартуем из точки $(0,1)$. Будем идти по ранжированной выборке, начиная с первого объекта; пусть текущий объект находится на позиции $k$, если он относится к классу "$-1$", то полнота не меняется, точность падает - соответственно, кривая опускается строго вниз. Если же объект относится к классу "$1$", то полнота увеличивается на $\frac{1}{\ell_{+}}$, точность растет, и кривая поднимается вправо и вверх. Площадь под этим участком можно аппроксимировать площадью прямоугольника с высотой, равной $\text{precision}@k$ и шириной $\frac{1}{\ell_{+}}$. При таком способе подсчёта площадь под $\text{PR}$-кривой будет совпадать со средней точностью:
$$\text{AUC-PR}=\frac{1}{\ell_{+}}\sum_{i=1}^{\ell}[y_{k}=1]\text{precision}@k.$$

Несмотря на указанные различия, между $\text{ROC-}$ и $PR$-кривой имеется тесная связь. Так, можно показать. что если $\text{ROC}$-кривая одного алгоритма лежит полностью над $\text{ROC}$-кривой другого алгоритма, то и $\text{PR}$-кривая одного лежит над $\text{PR}$-кривой другого.