Чтобы обучить регрессионые модели, необходимо определиться, как оценивать их качество. Пусть $y$ - значение целевой переменной, $a$ - прогноз модели.

- $MSE$ и $R^{2}$:
Основной способ посчитать отклонение -  посчитать квадрат разности:
$$L(y,a) = (a-y)^{2}$$
Благодаря своей дифференцируемости эта функция чаще всего используется в задачах регрессии. Основанный на ней функционал называется среднеквадратичным отклонением:
$$MSE(a, X) = \frac{1}{\ell}\sum_{i=1}^{\ell}(a(x_{i})-y_{i})^{2}$$
Но у $MSE$ есть одна проблема, которая заключается в её плохой интерпретированности, так как она не сохраняет единицы измерения, чтобы избежать этой проблемы, используют корень из среднеквадратичного отклонения(RMSE - Root Mean Square Error):
$$RMSE(a,X)=\sqrt{ \frac{1}{\ell}\sum_{i=1}^{\ell}(a(x_{i})-y_{i})^{2} }$$
Хотя и $MSE$ хорошо подходит для сравнения двух моделей, но оценить насколько правильно работает модель нельзя, так как значение отклонения, равное 10, может значить, о том, что модель хорошо работает если таргет большой (примерно в интервале от 10000 до 100000), а если целевая переменная лежит в интервале от 0 до 1, то модель работает плохо. Поэтому используют **коэффициент детерминации**($R^{2}$):
$$R^{2}(a,X)=1- \frac{ \sum_{i=1}^{\ell}(a(x_{i})-y_{i})^{2} }{\sum_{i=1}^{\ell}(y_{i}-\bar{y})^{2}}$$, где $\bar{y}$ - среднее значение целевой переменной.

