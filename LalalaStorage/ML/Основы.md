---
tags:
  - ml
links:
  - "[[Нотация Айверсона]]"
---

| **Машинное обучение** - наука, изучающая алгоритмы, автоматически улучшающиеся благодаря опыту.

| **Модель** - функция, отображающая объекты в предсказания. 
$a\in \mathcal{A}, \mathcal{A}$ - семейство моделей.
$a: X\to Y$ - алгоритм, модель.
Пример: линейные модели:
	$\mathcal{A} = \{ a(x) = w_{0} + w_{1}x_{1}+\dots+w_{d}x_{d} \ | w_{0},w_{1}, \dots,w_{d} \in \mathbb{R}  \}$

#### Метрики качества

Метрики необходимы для того, чтобы понять насколько хорошей получилась наша модель.

1. **Бизнес метрики** - самый высокий уровень. Пример: будущий доход сервиса. Их трудно измерить в моменте, так как они зависят сложным образом от всех наших усилий, не только от машинного обучения.
2. **Онлайн(online) метрики** - характеристики работающей системы, с помощью которых можно попробовать оценить поведение бизнес метрик. Примеры: медианная длина сессии в онлайн игре, среднее количество бананов, которые остались в конце рабочего дня.
3. Также в качестве метрики может служить субъективное впечатление. Чтобы оценить проект до его выхода в продакт, нанимают специальных людей для оценки, которых называют асессорами. Пример: оценка качества улучшения сервисов или релевантность выдачи в поисковой системе.
4. **Оффлайн(offline) метрики** - оценка отклонений предсказания модели от истинных значений таргета. Пример: среднеквадратичное отклонение, точность предсказания. Асессорскую оценку тоже можно считать оффлайн метрикой.

Цель задач состоит в том, чтобы найти такую модель, чтобы значения метрик были оптимальными.

#### Данные

| **Объект** - для чего делаем прогноз/анализ. Обозначение: $x$.
$x = \{ x_{1},x_{2},\dots,x_{d} \}$ - $d$ признаков.

| **Ответ, целевая переменная, таргет** - то, что мы предсказываем. Обозначение: $y$.

| $X$ - множество объектов

| $Y$ - множество ответов

| **Признаки, факторы, features** - характеристики объектов.

| **Признаковое описание** - совокупность признаков, которые имеет определённый объект.

Типы признаков:
1. Бинарные. $\{ 0,1 \}$. Можно работать с ними как с численными и как с категориальными.
2. Числовые. $\mathbb{R}$. Пример: рост, доход.
3. Категориальные. $\{ c_{1}, \dots,c_{n} \}$ - неупорядоченные без метрики. Пример: профессия человека, день недели.
4. Ординальные. $\{ c_{1},\dots,c_{n} \}$ - с частичным порядком. Пример: тип альбома(сингл, ep, альбом) при рекомендации песен.
5. set-valued $\subset C=\{ c_{1},\dots c_{n} \}$. В одном признаке несколько значений: жанры альбома.
6. Признаки со сложной структурой.

| **Обучающая выборка** - набор пар: объект-ответ. Обозначение: $X=\{ x_{i},y_{i} \}_{i=1}^{\ell}, \ \ell$ -размер обучающей выборки.

| **Feature engineering** - процесс извлечения признаков из сложно устроенных данных.  

Если все признаки являются численными, то таблицу можно представить в виде **матрицы объектов-признаков**.

Также в данных могут встретиться некоторые проблемы:
1. **Пропуски**. В примере табличных данных выше нам неизвестен возраст Васи. Объекты или признаки, в которых есть пропуски, можно удалять из выборки, если данных много. Но если пропусков много, то можно удалить слишком много данных.
2. **Выбросы** - объекты, которые не являются корректными примерами из-за неправильно посчитанных признаков, ошибки сбора данных или чего-то еще. Например, в датасете с информацией о клиентах банка, возраст одного человека равен 140, что является совсем нетипичным. Выбросы могут быть в результате ошибки при сборке данных или быть просто аномалиями. Если выбросами являются ошибки, то их лучше удалить, в случаях с аномалиями необходимо обработать всё отдельно.
3. **Ошибка разметки**. Пример: данные собираются с помощью людей, тогда некоторые таргеты будут отмечены неверно.
4. **Data Drift**. Проблема изменения данных со временем. Например: изменение схемы сбора данных или изменение распределения данных. Для решения нужно следить за данными и вовремя обновлять модель.
5. Некоторые признаки могут оказаться **шумовыми**, то есть не имеющими никакого отношения к целевой переменной и к решаемой задаче. Примером, скорее всего, может служить признак «фаза луны в день первого экзамена» в задаче предсказания успешности прохождения сессии студентом.
#### Типы задач

6. Supervised Learning (Обучение с учителем) - в множестве объектов есть правильные ответы.
    1. $Y=\mathbb{R}$ или $Y=\mathbb{R}^{M}$ - регрессия. Примеры: предсказание продолжительности на каршеринге, спрос на товар в конкретный день или погода в вашем городе на завтра(формирует вектор).
    2. $Y=0,1$ - бинарная классификация. Пример: сдаст ли студент сессию, кликнет ли пользователь по ссылке и т.д.
    3. $Y=1,…,K$ - многоклассовая классификация. Пример: определение предметной области статьи.
    4. $Y=\{0,1\}^{K}$ - многоклассовая классификация с пересекающимися классами. Пример: определение тегов для ресторана.
    5. $Y$ - конечное упорядоченное множество - ранжирование. Пример: задача ранжирования поисковой выдачи.
7. Unsupervised Learning (Обучение без учителя). Задачи, в которых у нас имеются только объекты, но нет ответов.
    1. Кластеризация - задача разделения объектов на группы, обладающие некоторыми свойствами. $X=\{ (x_{i}) \}_{i=1}^{\ell}$ Пример: кластеризация документов электронной библиотеки.
    2. Оценивание плотности - задача приближения распределения объектов.
    3. Визуализация - задача изображения двумерных или трёхмерных объектов в двумерном или трёхмерном пространстве таким образом, чтобы между объектами сохранялось как можно больше зависимостей и отношений между ними.
    4. Понижение размерности(Уменьшение признаков модели с сохранением уровня работы модели)
8. Reinforcement Learning (Обучение с подкреплением)

### Алгоритм обучения

| **Настраиваемые параметры** - параметры модели, которые восстанавливаются по датасету.

| **Обучение** - процесс поиска оптимального алгоритма(модели).

| **Функция потерь, loss** - это математическая **функция**, которая измеряет, насколько хорошо прогнозы модели соответствуют истинным результатам. Обозначение:
	$L: Y\times Y\to \mathbb{R}_{+}$ 
Примеры:
	$L = (y-z)^{2}$ - для регрессии
	$L=[y\neq z]$ - для классификации. ([[Нотация Айверсона|Нотация Айверсона]])
	, где $z$ - модель

| **Функционал ошибки**: $Q(a,X) = \frac{1}{\ell}\sum_{i=1}^{\ell}L(y_{i}, a(x_{i}))$

| **Задача обучения**:
	$$Q(a,X)\longrightarrow \min_{a\in \mathcal{A}}$$

| **Гиперпараметр** - параметр, который задаётся до обучения модели.

### Выбор модели, переобучение

| **Обобщающая способность** - способность модели выучить общие закономерности.

Чтобы модель не выучила все данные, то датасет разделяют на 2 части: **train** датасет и **test** датасет.

| **Generalization** - событие, при котором модель поняла данные и начала делать хорошие предсказания.

| **Переобучение** - ситуация, когда модель слишком сильно подстроилась под данные. Выявить данное состояние модели можно при помощи оценки модели на отложенной(тестовой) выборке или изучив получившиеся веса модели.

| **Concept drift** - изменение зависимости между признаками и таргетом.