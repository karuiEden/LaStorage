---
tags:
  - ml
links:
  - "[[LalalaStorage/ML/Основы|Основы]]"
---
1. *Метод отложенной выборки*. То есть разбиваем выборку на 2: обучающую и контрольную. Следовательно, обучаем модель на обучающей выборке, а затем проверяем модель на контрольной выборке. Проблема такого подхода состоит в том, что мы не можем предсказать какой бы результат модель выдавала бы на данных из контрольной выборке, ну и выборки могут оказаться неравномерны распределены, что также приведёт к низкому результату качества модели.
2. *Кросс-валидация*. Данный метод состоит в том, что мы разбиваем выборку на $k$ блоков $X_{1},X_{2},\dots,X_{k}$ и обучаем $k$ моделей $a_{1}(x),a_{2}(x),\dots,a_{k}(x)$ на всех блоках кроме $i$-ого, затем проверяем качество моделей и усредняем его, получая общее качество модели. Но с ним встаёт вопрос как получить финальную модель, если на этих данных модель хорошо работала, тогда справедливо 2 варианта: 
	1. Обучить модель на всех этих данных, так как модели обучились на более маленьких блоках, следовательно, на большем количестве данных модель должна стать ещё лучше
	2. Если обучить модель на всей выборке нет возможности, то тогда можно использовать *композицию* моделей. Например: усреднить прогнозы моделей и использовать их в финальном предсказании.
	