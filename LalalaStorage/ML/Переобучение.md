*Тэги:* ML
**Переобучение** - ситуация, когда качество модели на train данных значительно лучше, чем на validation/test.

## Борьба с ним

1. Увеличение данных.
2. Cross Validation
3. Подбор гиперпараметров модели

Последние два способа используются в случае, если кол-во данных увеличить не получается.

### Cross Validation

Cross-validation - это процедура, при которой мы разделяем весь датасет на несколько частей, и одну из частей используем для теста, а остальные для обучения. Здесь мы разберем метод **k-Fold**.
![[Pasted image 20241003182839.png]]

На рисунке мы разделили датасет на 4 равные части. Для первого случая (Fold 1) мы использовали для обучения 2,3,4 части, а в качестве тестовой выборки мы использовали 1-ую часть и посчитали метрики на ней. Для второго случая (Fold 2) мы обучались на частях 1,3,4 и посчитали метрики на 2-ой части. И так далее. И после мы усреднили метрики, полученные на каждой части.

Псевдо-алгоритм, получается, такой:

1. Выбираем k - количество частей, на которые разобьется наш обучающий датасет;
2. for i=1..k
    - Обучим модель на всех частях датасета, кроме i-ой.
    - Посчитаем метрики или предсказания для i-ой части
3. Саггрегируем все предсказания (например, усредним метрики)

Таким образом мы сможем получить более объективные оценки предсказательной способности нашей модели, использовав весь датасет как train и как test, при этом не создав утечек данных.

### Подбор гиперпараметров

Иногда кросс-валидация может не помочь справится с переобучением. Поэтому можно попробовать подобрать гиперпараметры к модели. Но делать это вручную бывает довольно тяжело и долго, поэтому используют класс из библиотеки Sklearn под названием [[Sklearn#`GridSearchCV()`|GridSearchCV]] . 