Тэги: ML

## Разделение датасета

Необходимо удалить целевую переменную из датасета:

```python
X = df.drop(columns='MainFeature').values

Y = df['MainFeature'].values
```

Затем мы должны распределить данные между двумя датасетами: Train и Test. При разделении данных, их можно перемешать для более эффективного обучения.

```python
from sklearn.model_selection import train_test_split

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, shuffle=True) # test_size - размер тестового датасета, shuffle - перемешивание данных

```

## Масштабирование данных

Для обучения модели необходимо привести все данные к одному масштабу, так как при обучении модели с данными в разных масштабах может создать байес. 

Например, переменная, находящаяся в диапазоне от 0 до 1000, будет превосходить переменную, находящуюся в диапазоне от 0 до 1. Использование этих переменных без стандартизации даст переменной с большим диапазоном вес 1000 в анализе. Преобразование данных в сопоставимые шкалы может предотвратить эту проблему. Типичные процедуры стандартизации данных выравнивают диапазон и/или изменчивость данных.
Как мы говорили в лекции часто необходимо привести все признаки к одному масштабу. Для этого существует библиотека [[Sklearn#Scaling data|sklearn]], которая предоставляет методы рескейлинга данных. На этом семинаре мы рассмотрим два основных: `StandardScaler()` и `MinMaxScaler()`. У каждого скейлера есть два метода: `.fit()` и `.transform()`.

`StandardScaler()` во время `.fit()` для каждого признака xi считает среднее μi и стандартное отклонение σi на обучающем датасете. Во время `.transform()` к каждому признаку применяется:

$$x^i_{new}=\frac{x_i−μ_i}{σi}$$  

`MinMaxScaler()` во время `.fit()` для каждого признака xi считает минимум xi,min и максимум xi,max на обучающем датасете. Во время `.transform()` к каждому признаку применяется:

$$x^i_{new}=\frac{x_i−x_{i,min}}{x_{i,max}−x_{i,min}}$$

Важно, чтобы статистика считалась только на тренировочном датасете, так как иначе модель получит данные с тренировочной, что может привести к неожиданному результату.