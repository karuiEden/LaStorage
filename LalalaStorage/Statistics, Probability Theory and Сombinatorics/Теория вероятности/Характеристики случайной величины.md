### Математическое ожидание

| Если случайная величина $X$ принимает значения $x_{1},x_{2},\dots,x_{n}$, то её **математическое ожидание(или среднее значение)** равно: $$\mathbb{E}(X)=\sum_{i=1}^{n}x_{i}P(X=x_{i})$$
#### Свойства математического ожидания

1. Умножение на число:
	| $\mathbb{E}(aX)=a\mathbb{E}(x) \ \ \forall X,a\in \mathbb{R}$
	*Док-во:*
	$$\mathbb{E}(aX)=\sum_{i=1}^{n}a\cdot x_{i}P(X=x_{i})=a\sum_{i=1}^{n}x_{i}P(X=x_{i})=a\cdot\mathbb{E}(X)$$
2. Сумма мат ожиданий:
	$$\mathbb{E}(X+Y)=\mathbb{E}(X)+\mathbb{E}(Y) \ \ \forall X,Y$$
	*Док-во*:
	$$\mathbb{E}(X+Y)=\sum_{i=1}^{n}(x_{i}P(X=x_{i})+y_{i}P(Y=y_{i}))=\sum_{i=1}^{n}x_{i}P(X=x_{i})+\sum_{i=1}^{n}y_{i}P(Y=y_{i})=\mathbb{E}(X)+\mathbb{E}(Y)$$
3.  Константа:
	| Если $X$ является постоянной $a$, то $\mathbb{E}(X)=a$
	*Док-во:* Если $X$ постоянна $\forall w\in\Omega$, то $P(X=x_{i})=P(X=a)=P(\Omega)=1$
	$$\mathbb{E}(X)=\sum_{i=1}^{n}x_{i}P(X=x_{i})=a\cdot P(X=a)=a$$
### Дисперсия

| Если случайная величина $X$ имеет значения $x_{1},x_{2},\dots,x_{n}$, то её **дисперсия** равна
$$Var(X)=\sum_{i=1}^{n}(x_{i}-\mathbb{E}(X))^{2}\cdot P(X=x_{i})=\mathbb{E}((X-\mathbb{E}(X))^{2}).$$

### Взаимосвязь случайных величин

Распишем дисперсию суммы двух случайных величин:$$
Var(X+Y)=\mathbb{E}((X+Y-\mathbb{E}(X+Y))^{2})= \mathbb{E}((X+Y-\mathbb{E}(X)-\mathbb{E}(Y))^{2})=
$$
$$=\mathbb{E}((X-\mathbb{E}(X))+(Y-\mathbb{E}(Y))^{2})=\mathbb{E}((X-\mathbb{E}(X))^{2}+2(X-\mathbb{E}(X))(Y-\mathbb{E}(Y))+(Y-\mathbb{E}(Y))^{2})=$$
$$=Var(X)+Var(Y)+2\mathbb{E}(X-\mathbb{E}(X))(Y-\mathbb{E}(Y))$$
Как мы можем заметить, у нас получилось две дисперсии $Var(X),Var(Y)$ и ещё один новый член, который показывает взаимосвязь случайных величин. Если его раскрыть, то получим формулу для его счёта:
$$\mathbb{E}((X-\mathbb{E}(X))(Y-\mathbb{E}(Y)))=\mathbb{E}(XY-X\mathbb{E}(Y)-Y\mathbb{E}(X)+\mathbb{E}(X)\mathbb{E}(Y))=$$
$$\mathbb{E}(XY)-2\mathbb{E}(X)\mathbb{E}(Y)+\mathbb{E}(X)\mathbb{E}(Y)=\mathbb{E}(XY)-\mathbb{E}(X)\mathbb{E}(Y)$$
Такой показатель, отражающий связь двух случайных величин, называется **ковариацией**

| **Ковариацией** двух случайных величин $X$ и $Y$:
$$Cov(X,Y)=\mathbb{E}(XY)-\mathbb{E}(X)\cdot\mathbb{E(Y)}$$
Также есть две формулы через суммы(В $X$ есть значения $x_{1},x_{2},\dots,x_{n}$; В $Y$ есть значения $y_{1},y_{2},\dots,y_{m}$, $\mathbb{E}(X)=\mu_{X}, \ \mathbb{E}(Y)=\mu_{Y}$)
$$1. \ Cov(X,Y)=\mathbb{E}(XY)-\mathbb{E}(X)\mathbb{E}(Y)=\sum_{i=1}^{n}\sum_{j=1}^{m}(x_{i}-\mu_{x})\cdot(y_{j}-\mu_{y})\cdot P(X=x_{i} \ \cap Y=y_{i});$$
$$2. \ Cov(X,Y)=\mathbb{E}(XY)-\mathbb{E}(X)\mathbb{E}(Y)=\sum_{i=1}^{n}\sum_{j=1}^{m}x_{i}\cdot y_{j}\cdot P(X=x_{i} \ \cap Y=y_{i})-\mu_{x}\cdot\mu_{y}$$
Ковариация может быть как положительной, так и отрицательной. Она будет положительной, если с ростом одной случайной величины значения второй будут иметь тенденцию возрастать. Будет отрицательной, если убывать.

| $Var(X + Y)=Var(X)+Var(Y)-2Cov(X,Y) \ \ \ \forall X,Y$

| Если $P(X=x \ \cap Y=y) = P(X=x)\cdot P(Y=y) \ \ \forall x,y,\text{ то }X,Y \text{- независимые}$

Ковариация для независимых величин равна нулю.



